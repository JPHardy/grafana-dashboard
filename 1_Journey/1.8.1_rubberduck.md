prompt: I am having a hard time deploying a grafana dashboard in github codepsaces over a minikube. The grafana gets deployed but not the dashboards

output:
Deploying Grafana dashboards in GitHub Codespaces over Minikube can present challenges, especially if the dashboards aren't being deployed properly. Here's a step-by-step approach to troubleshoot and resolve the issue:

---

### 1. **Verify Dashboard Configuration**
   - Ensure your dashboards are defined correctly as JSON files.
   - Place them in the correct directory for provisioning. By default, Grafana looks for dashboards in `/var/lib/grafana/dashboards` or a custom path you specify in the `provisioning` configuration.

prompt: I am using bitnami templates 
output:
If you're using Bitnami templates to deploy Grafana, the setup will differ slightly since Bitnami charts come with pre-configured templates and options for customization. Here's how you can ensure your Grafana dashboards are deployed correctly:

---

### 1. **Enable Dashboard Provisioning in Bitnami Chart**
   - Bitnami Helm charts for Grafana allow you to provision dashboards through ConfigMaps or by mounting them as files.
   - First, verify the **values.yaml** file for your Bitnami chart deployment and ensure the following settings are enabled:

     ```yaml
     dashboardsConfigMaps:
       enabled: true

     dashboards:
       example-dashboard:
         json: |
           {
             "uid": "example",
             "title": "Example Dashboard",
             ...
           }
     ```

---

prompt: what is the different betnween dashboardprovider and dashboardcofigmaps can they be used at the same time 
output:
The **difference between `dashboardProvider` and `dashboardConfigMaps`** lies in how they manage and provision dashboards for Grafana. Here's an explanation of each and whether they can be used together:

---

### **1. DashboardProvider**
- **Definition**: A mechanism native to Grafana, defined in `provisioning/dashboards.yaml`. It tells Grafana where to look for dashboards and how to load them (e.g., from files or a URL).
- **How It Works**: 
  - Grafana loads dashboards directly from a specified directory (`path`) or other sources like APIs.
  - Configurations for providers are defined in YAML files like this:

    ```yaml
    apiVersion: 1
    providers:
      - name: 'default'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        options:
          path: /var/lib/grafana/dashboards
    ```

- **Use Case**: When you have dashboards as static JSON files, stored locally or mounted into the Grafana container (e.g., via `extraVolumes`).

---

### **2. DashboardConfigMaps**
- **Definition**: A feature provided by Helm charts (e.g., Bitnami or other charts) that allows you to provision Grafana dashboards using Kubernetes ConfigMaps.
- **How It Works**:
  - You define each dashboard as a JSON file in a ConfigMap.
  - The ConfigMap is referenced in the Helm chart configuration (e.g., in `values.yaml`).
  - The Helm chart automatically mounts the ConfigMap as a volume or injects the dashboards into the appropriate directory in the Grafana container.

- **Example ConfigMap**:
  ```yaml
  apiVersion: v1
  kind: ConfigMap
  metadata:
    name: grafana-dashboard-example
    labels:
      grafana_dashboard: "1"
  data:
    dashboard.json: |
      {
        "uid": "example",
        "title": "Example Dashboard",
        ...
      }
  ```

- **Use Case**: When deploying dashboards in Kubernetes, using ConfigMaps is a clean way to manage them as Kubernetes-native resources.

---

### **Key Differences**
| Feature              | DashboardProvider                          | DashboardConfigMaps                        |
|----------------------|--------------------------------------------|-------------------------------------------|
| **Provision Source** | Local file paths or URLs                  | Kubernetes ConfigMaps                     |
| **Integration**      | Native to Grafana                         | Provided by Helm charts like Bitnami      |
| **Flexibility**      | Requires manual volume mounting or file sync | Kubernetes-native, integrates easily with cluster |
| **Complexity**       | Slightly more manual setup                | Automated with Helm charts                |

---

### **Can They Be Used Together?**
Yes, **`dashboardProvider`** and **`dashboardConfigMaps`** can be used together, but they serve different purposes. 

- **Use Case for Both**:
  - If you have some dashboards stored as local files (managed via `dashboardProvider`) and others managed through Kubernetes ConfigMaps, you can configure both.
  - Grafana will load dashboards from all configured providers.

- **How to Combine**:
  1. Define a `dashboardProvider` in your provisioning configuration to load dashboards from a local directory.
  2. Use the Helm chart's `dashboardConfigMaps` feature to mount additional dashboards via ConfigMaps.

  Example setup in Helm **values.yaml**:
  ```yaml
  dashboardsConfigMaps:
    - grafana-dashboard-example

  extraVolumeMounts:
    - name: custom-dashboards
      mountPath: /var/lib/grafana/dashboards

  extraVolumes:
    - name: custom-dashboards
      hostPath:
        path: /path/to/local/dashboards
        type: Directory
  ```

---

### **Considerations When Using Both**
- **Namespace Conflicts**: Ensure that dashboard `uid`s are unique to avoid collisions.
- **Performance**: Loading dashboards from multiple sources can increase startup time.
- **Management Complexity**: Combining approaches requires careful tracking of where dashboards are stored and updated.

Using both approaches simultaneously can provide flexibility but may increase the complexity of managing dashboards. If possible, stick to one method for simplicity. Let me know if you'd like help configuring them!

prompt: I want to deploy with configMaps how is this file > admin:
  ## @param admin.user Grafana admin username
  ##
  user: "admin"
  ## @param admin.password Admin password. If a password is not provided a random password will be generated
  ##
  ## Test this to make sure the values yaml used your values not the default values...if the structure fails it defaults back to default values
  password: "your-password"

## @section Grafana Deployment parameters
grafana:
  envVars:
    - name: GF_LOG_LEVEL
      value: debug
  ## @param grafana.replicaCount Number of Grafana nodes
  ##
  replicaCount: 1
  persistence:
    enabled: true
    size: 100Mi
  service:
    type: NodePort
    port: 3000
    nodePort: 30000
  extraVolumes:
    - name: grafana-storage
      emptyDir: {}
  volumeMounts:
    - name: grafana-storage
      mountPath: /opt/bitnami/grafana
    - name: grafana-dashboard-config
      mountPath: /opt/bitnami/grafana/dashboards
      readOnly: true
    - name: grafana-datasources
      mountPath: /opt/bitnami/grafana/provisioning/datasources
  volumes:
    - name: grafana-datasources
      configMap:
        name: grafana-datasources
    - name: grafana-secrets
      secret:
        name: grafana-datasource-secret

dashboardsConfigMaps:
  enabled: true
   - configMapName: grafana-dashboard-config
     fileName: grafana_dashboard_config.json

## Service parameters
##
service:
  ## @param service.type Kubernetes Service type
  ##
  type: ClusterIP
  ## @param service.clusterIP Grafana service Cluster IP
  ## e.g.:
  ## clusterIP: None
  ##
  # clusterIP: ""
  ## @param service.ports.grafana Grafana service port
  ##
  ports:
    grafana: 3000

output:
Here’s an explanation of your provided **values.yaml** file for deploying Grafana with ConfigMaps for dashboard provisioning, along with adjustments to ensure it works as intended:

---
output:

### **Key Sections and Explanations**

#### **Admin User Configuration**
```yaml
admin:
  user: "admin"
  password: "your-password"
```
- This sets the Grafana admin username and password. Ensure you set these explicitly to avoid default values being applied if the structure fails.

#### **Grafana Deployment Parameters**
```yaml
grafana:
  envVars:
    - name: GF_LOG_LEVEL
      value: debug
  replicaCount: 1
  persistence:
    enabled: true
    size: 100Mi
```
- **`envVars`**: Enables debug logging for troubleshooting.
- **`replicaCount`**: Deploys a single Grafana pod.
- **`persistence`**: Ensures dashboards and data are stored persistently. You may want to check if the `size` of `100Mi` meets your needs.

#### **Volume Mounts**
```yaml
  extraVolumes:
    - name: grafana-storage
      emptyDir: {}
  volumeMounts:
    - name: grafana-storage
      mountPath: /opt/bitnami/grafana
    - name: grafana-dashboard-config
      mountPath: /opt/bitnami/grafana/dashboards
      readOnly: true
    - name: grafana-datasources
      mountPath: /opt/bitnami/grafana/provisioning/datasources
```
- This mounts:
  - **`grafana-storage`** for general Grafana data.
  - **`grafana-dashboard-config`** for dashboards in `/opt/bitnami/grafana/dashboards`. This is where ConfigMaps with dashboards will be mounted.
  - **`grafana-datasources`** for data source provisioning files.

#### **ConfigMaps for Dashboards**
```yaml
dashboardsConfigMaps:
  enabled: true
   - configMapName: grafana-dashboard-config
     fileName: grafana_dashboard_config.json
```
- **`enabled: true`**: Activates the ConfigMap-based dashboard provisioning feature.
- **`configMapName`**: Points to the ConfigMap (`grafana-dashboard-config`) that contains the dashboard JSON.
- **`fileName`**: Specifies the file name inside the ConfigMap to use as the dashboard.

Ensure the ConfigMap is created in the cluster with the correct name (`grafana-dashboard-config`) and structure.

---

### **ConfigMap Example for Dashboards**
Here’s an example of how the ConfigMap for the dashboards should look:

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboard-config
  labels:
    grafana_dashboard: "1"
data:
  grafana_dashboard_config.json: |
    {
      "uid": "example",
      "title": "Example Dashboard",
      "panels": [],
      "version": 1,
      ...
    }
```

---

### **Service Parameters**
```yaml
service:
  type: ClusterIP
  ports:
    grafana: 3000
```
- Configures the service type and ports:
  - **`type: ClusterIP`**: Makes Grafana accessible only within the cluster.
  - **`ports.grafana: 3000`**: Sets Grafana to listen on port 3000.

---

### **Issues to Address**
1. **Indentation Error in `dashboardsConfigMaps`:**
   The list under `dashboardsConfigMaps` is incorrectly indented. It should be:
   ```yaml
   dashboardsConfigMaps:
     enabled: true
     configMaps:
       - configMapName: grafana-dashboard-config
         fileName: grafana_dashboard_config.json
   ```

2. **Volume Mount Issues:**
   Ensure the `volumeMounts` and `volumes` sections align with the Helm chart's structure. Check for correct mapping of ConfigMap data.

3. **Datasource Configuration:**
   Verify the `grafana-datasources` ConfigMap and secret (`grafana-datasource-secret`) are correctly created in the cluster.

---

### **Steps to Deploy**
1. **Create ConfigMaps:**
   - Create the ConfigMap for dashboards (`grafana-dashboard-config`).
   - Create the ConfigMap and secret for data sources (`grafana-datasources` and `grafana-datasource-secret`).

2. **Apply ConfigMaps:**
   ```bash
   kubectl apply -f grafana-dashboard-config.yaml
   kubectl apply -f grafana-datasources.yaml
   kubectl apply -f grafana-datasource-secret.yaml
   ```

3. **Deploy Grafana:**
   Use Helm to deploy Grafana with the updated `values.yaml`:
   ```bash
   helm upgrade --install grafana bitnami/grafana -f values.yaml
   ```

4. **Verify Deployment:**
   - Check if the ConfigMaps are mounted and dashboards loaded:
     ```bash
     kubectl logs -f <grafana-pod-name>
     ```

Let me know if you need further clarification or adjustments!

correct path :  helm upgrade grafana bitnami/grafana --namespace grafana-monitoring -f grafana-dashboard-deployment.yaml
prompt: I get this error
@rifaterdemsahin ➜ /workspaces/grafana-dashboard/6_Symbols/4_DashboardConfigMaps (main) $  helm upgrade grafana bitnami/grafana --namespace grafana-monitoring -f grafana-dashboard-deployment.yaml
coalesce.go:237: warning: skipped value for grafana.dashboardsConfigMaps: Not a table.
coalesce.go:237: warning: skipped value for grafana.dashboardsConfigMaps: Not a table.
Error: UPGRADE FAILED: template: grafana/templates/deployment.yaml:201:72: executing "grafana/templates/deployment.yaml" at <.configMapName>: can't evaluate field configMapName in type interface {}
@rifaterdemsahin ➜ /workspaces/grafana-dashboard/6_Symbols/4_DashboardConfigMaps (main) $ 

output:
>>>>
The error indicates an issue with the `dashboardsConfigMaps` section in your `grafana-dashboard-deployment.yaml` file. Specifically, Helm is interpreting the `dashboardsConfigMaps` section incorrectly due to improper formatting or structure.

Let’s address the problem step-by-step:

---

### **Key Error Points**

1. **Warning: `grafana.dashboardsConfigMaps: Not a table`**
   - This means Helm expects `dashboardsConfigMaps` to be a dictionary-like structure (a map or table), but the provided format is not correct.

2. **Error: `can't evaluate field configMapName in type interface {}`**
   - This implies that the `configMapName` field is missing or incorrectly structured in the `dashboardsConfigMaps` configuration.

---

### **Corrected Structure for `dashboardsConfigMaps`**

The `dashboardsConfigMaps` section should follow the expected structure for the Bitnami Grafana Helm chart. Here's the corrected YAML snippet:

```yaml
grafana:
  dashboardsConfigMaps:
    enabled: true
    configMaps:
      - configMapName: grafana-dashboard-config
        fileName: grafana_dashboard_config.json
```

- **`enabled`**: Ensures the `dashboardsConfigMaps` feature is active.
- **`configMaps`**: A list of ConfigMaps to be mounted, each with:
  - `configMapName`: The name of the ConfigMap in Kubernetes.
  - `fileName`: The specific file name inside the ConfigMap to use as the dashboard.

---

### **Other Potential Issues to Check**

#### 1. **ConfigMap Exists in Kubernetes**
Ensure the ConfigMap (`grafana-dashboard-config`) has been created and matches the name used in the `values.yaml`. You can verify it with:

```bash
kubectl get configmap -n grafana-monitoring
```

#### 2. **Proper Indentation in YAML**
YAML is indentation-sensitive. Any misalignment in spaces or dashes can lead to parsing errors. Ensure the indentation for `dashboardsConfigMaps` matches the example above.

#### 3. **Helm Chart Version Compatibility**
Verify the Helm chart version supports the `dashboardsConfigMaps` feature. You can check the version you are using with:

```bash
helm show chart bitnami/grafana
```

Ensure your chart version aligns with the documentation for `dashboardsConfigMaps`. If it's an older version, consider upgrading the Helm chart.

---

### **Testing the Fixed Deployment**

After making the corrections, try deploying again:

```bash
helm upgrade --install grafana bitnami/grafana --namespace grafana-monitoring -f grafana-dashboard-deployment.yaml
```

---

### **Debugging Further**

If you still encounter errors, debug with:
1. **Helm Template Output**:
   Render the Helm templates locally to inspect the final YAML:
   ```bash
   helm template grafana bitnami/grafana --namespace grafana-monitoring -f grafana-dashboard-deployment.yaml
   ```

2. **Check Logs**:
   Check the logs of the Grafana pod for errors related to dashboard provisioning:
   ```bash
   kubectl logs -f <grafana-pod-name> -n grafana-monitoring
   ```

Let me know if you need further clarification or assistance!
prompt: deployed
rifaterdemsahin ➜ /workspaces/grafana-dashboard/6_Symbols/4_DashboardConfigMaps (main) $ helm upgrade grafana bitnami/grafana --namespace grafana-monitoring -f grafana-dashboard-deployment.yaml
Release "grafana" has been upgraded. Happy Helming!
NAME: grafana
LAST DEPLOYED: Mon Jan 13 15:50:40 2025
NAMESPACE: grafana-monitoring
STATUS: deployed
REVISION: 2
TEST SUITE: None
NOTES:
CHART NAME: grafana
CHART VERSION: 11.4.2
APP VERSION: 11.4.0

Did you know there are enterprise versions of the Bitnami catalog? For enhanced secure software supply chain features, unlimited pulls from Docker, LTS support, or application customization, see Bitnami Premium or Tanzu Application Catalog. See https://www.arrow.com/globalecs/na/vendors/bitnami for more information.

** Please be patient while the chart is being deployed **

1. Get the application URL by running these commands:
    echo "Browse to http://127.0.0.1:8080"
    kubectl port-forward svc/grafana 8080:3000 &

2. Get the admin credentials:

    echo "User: admin"
    echo "Password: $(kubectl get secret grafana-admin --namespace grafana-monitoring -o jsonpath="{.data.GF_SECURITY_ADMIN_PASSWORD}" | base64 -d)"
# Note: Do not include grafana.validateValues.database here. See https://github.com/bitnami/charts/issues/20629


WARNING: There are "resources" sections in the chart not set. Using "resourcesPreset" is not recommended for production. For production installations, please set the following values according to your workload needs:
  - grafana.resources
+info https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
@rifaterdemsahin ➜ /workspaces/grafana-dashboard/6_Symbols/4_DashboardConfigMaps (main) $ 

prompt: deployed it but still cant see the dashboard coming from out configmap

output:
If you've successfully deployed Grafana but the dashboard from the ConfigMap is not appearing, here are some steps to debug and resolve the issue:

---

### **1. Verify the ConfigMap Data**
Ensure the ConfigMap for the dashboard is correctly created and contains valid JSON data for the dashboard.

Run:
```bash
kubectl get configmap grafana-dashboard-config -o yaml -n grafana-monitoring
```


 kubectl get configmap grafana-dashboard-config -o yaml -n grafana-monitoring
apiVersion: v1
data:
  grafana_dashboard_config: |
    {
       "dashboard": {
         "id": null,
         "title": "Random Walk Dashboard",
         "tags": [],
         "timezone": "browser",
         "schemaVersion": 16,
         "version": 0,
         "panels": [
           {
             "type": "graph",
             "title": "Random Walk",
             "gridPos": { "x": 0, "y": 0, "w": 24, "h": 9 },
             "datasource": "Random Walk Data",
             "targets": [
               {
                 "refId": "A",
                 "scenarioId": "random_walk"
               }
             ]
           }
         ]
       }
     }
kind: ConfigMap
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","data":{"grafana_dashboard_config":"{\n   \"dashboard\": {\n     \"id\": null,\n     \"title\": \"Random Walk Dashboard\",\n     \"tags\": [],\n     \"timezone\": \"browser\",\n     \"schemaVersion\": 16,\n     \"version\": 0,\n     \"panels\": [\n       {\n         \"type\": \"graph\",\n         \"title\": \"Random Walk\",\n         \"gridPos\": { \"x\": 0, \"y\": 0, \"w\": 24, \"h\": 9 },\n         \"datasource\": \"Random Walk Data\",\n         \"targets\": [\n           {\n             \"refId\": \"A\",\n             \"scenarioId\": \"random_walk\"\n           }\n         ]\n       }\n     ]\n   }\n }\n"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"grafana_dashboard":"1"},"name":"grafana-dashboard-config","namespace":"grafana-monitoring"}}
  creationTimestamp: "2025-01-13T14:26:03Z"
  labels:
    grafana_dashboard: "1"
  name: grafana-dashboard-config
  namespace: grafana-monitoring
  resourceVersion: "471"
  uid: a77c4f2a-b047-4f1b-9f1f-06e198b0bbf8

 output>>>

 From the ConfigMap content, it looks like the JSON structure for the dashboard might not be in the correct format that Grafana expects when provisioning dashboards. Specifically:

### Issues Observed:
1. **Top-Level Key (`dashboard`)**: 
   - Grafana expects the JSON in the ConfigMap to be directly a dashboard definition, not wrapped under a `dashboard` key. The content inside the `dashboard` key should be at the root level.
   
2. **Missing Required Fields**:
   - `overwrite: true` should be included in the JSON to ensure updates are applied during provisioning.

---

### Correct ConfigMap Format

Here’s how the ConfigMap should look:

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboard-config
  namespace: grafana-monitoring
  labels:
    grafana_dashboard: "1"
data:
  random-walk-dashboard.json: |
    {
      "id": null,
      "uid": "random-walk-dashboard",
      "title": "Random Walk Dashboard",
      "tags": [],
      "timezone": "browser",
      "schemaVersion": 16,
      "version": 0,
      "overwrite": true,
      "panels": [
        {
          "type": "graph",
          "title": "Random Walk",
          "gridPos": { "x": 0, "y": 0, "w": 24, "h": 9 },
          "datasource": "Random Walk Data",
          "targets": [
            {
              "refId": "A",
              "scenarioId": "random_walk"
            }
          ]
        }
      ]
    }
```

---

### Steps to Fix and Deploy

1. **Update the ConfigMap**:
   Replace the current ConfigMap content with the corrected structure:
   ```bash
   kubectl apply -f /workspaces/grafana-dashboard/6_Symbols/4_DashboardConfigMaps/configmap_randomwalk.yaml -n grafana-monitoring
   ```

2. **Verify Volume Mount in Pod**:
   Ensure the ConfigMap is mounted correctly. Check the directory in the Grafana pod:
   ```bash
   kubectl exec -it <grafana-pod-name> -n grafana-monitoring -- ls /opt/bitnami/grafana/dashboards
   ```

   Confirm the file `random-walk-dashboard.json` exists in the mounted path.

3. **Restart Grafana**:
   Restart the Grafana deployment to ensure it picks up the new ConfigMap:
   ```bash
   kubectl rollout restart deployment grafana -n grafana-monitoring
   ```

4. **Check Logs**:
   Inspect Grafana logs for dashboard provisioning activity:
   ```bash
   kubectl logs -f <grafana-pod-name> -n grafana-monitoring
   ```

---

### Debugging Further
If the dashboard still does not appear:
1. Manually validate the JSON by importing it into Grafana via the web UI to ensure there are no errors.
2. Confirm the provisioning configuration file (`provisioning/dashboards/*.yaml`) correctly points to `/opt/bitnami/grafana/dashboards`.

Let me know how it goes!


It looks like the `/opt/bitnami/grafana/dashboards` directory still doesn't exist inside the pod, even after restarting it.

### Next Steps:

1. **Create the `/opt/bitnami/grafana/dashboards` Directory**:
   You can manually create the `dashboards` directory to ensure the Grafana pod can use it. Run the following command to create the directory:
   ```bash
   kubectl exec -it grafana-f7d9c984d-xnqhm -n grafana-monitoring -- mkdir -p /opt/bitnami/grafana/dashboards
   ```

2. **Check Volume Mounts**:
   After creating the directory, confirm that the volume mount is properly applied by inspecting the pod's configuration:
   ```bash
   kubectl get pod grafana-f7d9c984d-xnqhm -n grafana-monitoring -o yaml
   ```

   @rifaterdemsahin ➜ /workspaces/grafana-dashboard/6_Symbols/4_DashboardConfigMaps (main) $ kubectl get pod grafana-f7d9c984d-xnqhm -n grafana-monitoring -o yaml
apiVersion: v1
kind: Pod
metadata:
  annotations:
    checksum/config: 19c20dc5bd07bc522511ffab5d9eac1446dcd3a6450e7bbfdf09a5d562286cec
    checksum/dashboard-provider: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
    checksum/secret: 4392d22dc063d7ffda1126edc47da819eefc80a1e3130abeb719c2232887e531
    kubectl.kubernetes.io/restartedAt: "2025-01-13T16:19:52Z"
  creationTimestamp: "2025-01-13T16:19:52Z"
  generateName: grafana-f7d9c984d-
  labels:
    app.kubernetes.io/component: grafana
    app.kubernetes.io/instance: grafana
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: grafana
    app.kubernetes.io/version: 11.4.0
    helm.sh/chart: grafana-11.4.2
    pod-template-hash: f7d9c984d
  name: grafana-f7d9c984d-xnqhm
  namespace: grafana-monitoring
  ownerReferences:
  - apiVersion: apps/v1
    blockOwnerDeletion: true
    controller: true
    kind: ReplicaSet
    name: grafana-f7d9c984d
    uid: 2a9c936d-37ac-4843-b6b0-d6f1427eb968
  resourceVersion: "6117"
  uid: 66ef68f7-a945-414b-b2ca-1cebad2f7fa0
spec:
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - podAffinityTerm:
          labelSelector:
            matchLabels:
              app.kubernetes.io/component: grafana
              app.kubernetes.io/instance: grafana
              app.kubernetes.io/name: grafana
          topologyKey: kubernetes.io/hostname
        weight: 1
  automountServiceAccountToken: false
  containers:
  - env:
    - name: GF_SECURITY_ADMIN_PASSWORD
      valueFrom:
        secretKeyRef:
          key: GF_SECURITY_ADMIN_PASSWORD
          name: grafana-admin
    envFrom:
    - configMapRef:
        name: grafana-envvars
    image: docker.io/bitnami/grafana:11.4.0-debian-12-r0
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 6
      initialDelaySeconds: 120
      periodSeconds: 10
      successThreshold: 1
      tcpSocket:
        port: dashboard
      timeoutSeconds: 5
    name: grafana
    ports:
    - containerPort: 3000
      name: dashboard
      protocol: TCP
    readinessProbe:
      failureThreshold: 6
      httpGet:
        path: /api/health
        port: dashboard
        scheme: HTTP
      initialDelaySeconds: 30
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 5
    resources:
      limits:
        cpu: 150m
        ephemeral-storage: 2Gi
        memory: 192Mi
      requests:
        cpu: 100m
        ephemeral-storage: 50Mi
        memory: 128Mi
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      privileged: false
      readOnlyRootFilesystem: true
      runAsGroup: 1001
      runAsNonRoot: true
      runAsUser: 1001
      seLinuxOptions: {}
      seccompProfile:
        type: RuntimeDefault
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /tmp
      name: empty-dir
      subPath: tmp-dir
    - mountPath: /opt/bitnami/grafana/conf
      name: empty-dir
      subPath: app-conf-dir
    - mountPath: /opt/bitnami/grafana/tmp
      name: empty-dir
      subPath: app-tmp-dir
    - mountPath: /bitnami/grafana
      name: empty-dir
      subPath: app-volume-dir
    - mountPath: /opt/bitnami/grafana/data
      name: data
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  nodeName: minikube
  preemptionPolicy: PreemptLowerPriority
  priority: 0
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext:
    fsGroup: 1001
    fsGroupChangePolicy: Always
  serviceAccount: grafana
  serviceAccountName: grafana
  terminationGracePeriodSeconds: 30
  tolerations:
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
    tolerationSeconds: 300
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
    tolerationSeconds: 300
  volumes:
  - emptyDir: {}
    name: empty-dir
  - name: data
    persistentVolumeClaim:
      claimName: grafana
  - emptyDir: {}
    name: grafana-storage
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2025-01-13T16:19:54Z"
    status: "True"
    type: PodReadyToStartContainers
  - lastProbeTime: null
    lastTransitionTime: "2025-01-13T16:19:53Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2025-01-13T16:20:23Z"
    status: "True"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2025-01-13T16:20:23Z"
    status: "True"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2025-01-13T16:19:52Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - containerID: docker://73acd77163d368d10cc00dd671b36106eaed628bf87ddbb8de56b7bec12ffe63
    image: bitnami/grafana:11.4.0-debian-12-r0
    imageID: docker-pullable://bitnami/grafana@sha256:cb8ab551567670a68f44052587c169339732fa7e0f4d806aecfd6b1e5889c626
    lastState: {}
    name: grafana
    ready: true
    restartCount: 0
    started: true
    state:
      running:
        startedAt: "2025-01-13T16:19:53Z"
    volumeMounts:
    - mountPath: /tmp
      name: empty-dir
    - mountPath: /opt/bitnami/grafana/conf
      name: empty-dir
    - mountPath: /opt/bitnami/grafana/tmp
      name: empty-dir
    - mountPath: /bitnami/grafana
      name: empty-dir
    - mountPath: /opt/bitnami/grafana/data
      name: data
  hostIP: 192.168.49.2
  hostIPs:
  - ip: 192.168.49.2
  phase: Running
  podIP: 10.244.0.6
  podIPs:
  - ip: 10.244.0.6
  qosClass: Burstable
  startTime: "2025-01-13T16:19:53Z"
@rifaterdemsahin ➜ /workspaces/grafana-dashboard/6_Symbols/4_DashboardConfigMaps (main) $ 

output:
It looks like the pod configuration is set up with several `emptyDir` volumes for various paths, but there is no indication of the `dashboards` directory being explicitly mounted. The pod's current configuration does not reference the `grafana-dashboard-config` ConfigMap for the dashboards.

### To fix this, follow these steps:

1. **Add a Volume for Dashboards**:
   You need to ensure the `grafana-dashboard-config` ConfigMap is mounted as a volume inside the Grafana container. Update the pod or deployment configuration to include the volume.

   Here’s an example of how to do that:

   ```yaml
   volumes:
     - name: grafana-dashboard-config
       configMap:
         name: grafana-dashboard-config
   ```

2. **Update the `volumeMounts` for Dashboards**:
   Ensure that the dashboard directory is correctly mounted inside the container. Add the following to the `volumeMounts` section of your pod configuration:

   ```yaml
   volumeMounts:
     - mountPath: /opt/bitnami/grafana/dashboards
       name: grafana-dashboard-config
   ```

3. **Apply Changes**:
   After modifying the configuration, apply the changes to the deployment:
   ```bash
   kubectl apply -f grafana-deployment.yaml
   ```

   If you are using Helm for deployment, you can update the `values.yaml` file and then run:
   ```bash
   helm upgrade grafana bitnami/grafana -f values.yaml -n grafana-monitoring
   ```

4. **Restart the Pod**:
   Restart the pod to ensure the changes take effect:
   ```bash
   kubectl rollout restart deployment grafana -n grafana-monitoring
   ```

After completing these steps, the `dashboards` directory should be populated with your ConfigMap data and available to Grafana. Let me know if you need further assistance!