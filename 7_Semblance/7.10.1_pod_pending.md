@rifaterdemsahin ➜ /workspaces/grafana-dashboard (main) $ 
@rifaterdemsahin ➜ /workspaces/grafana-dashboard (main) $ kubectl port-forward -n grafana-monitoring svc/grafana 3000:3000 
error: unable to forward port because pod is not running. Current status=Pending
@rifaterdemsahin ➜ /workspaces/grafana-dashboard (main) $ kubectl port-forward -n grafana-monitoring svc/grafana 3000:3000 
error: unable to forward port because pod is not running. Current status=Pending
@rifaterdemsahin ➜ /workspaces/grafana-dashboard (main) $ kubectl port-forward -n grafana-monitoring svc/grafana 3000:3000 
error: unable to forward port because pod is not running. Current status=Pending
@rifaterdemsahin ➜ /workspaces/grafana-dashboard (main) $ kubectl port-forward -n grafana-monitoring svc/grafana 3000:3000 
error: unable to forward port because pod is not running. Current status=Pending
@rifaterdemsahin ➜ /workspaces/grafana-dashboard (main) $ 


It looks like the Grafana pod in your `grafana-monitoring` namespace is stuck in a `Pending` state, which is why you're unable to forward the port. Here are a few steps you can take to troubleshoot this issue:

1. **Check Pod Status**: Use `kubectl get pods -n grafana-monitoring` to see the status of all pods in the namespace. This can give you more details about why the pod is pending.

2. **Describe the Pod**: Use `kubectl describe pod <pod-name> -n grafana-monitoring` to get detailed information about the pod. Look for events at the bottom of the output that might indicate why the pod is not starting.

3. **Check Node Resources**: Ensure that there are enough resources (CPU, memory) available on the nodes to schedule the pod. You can check node resources with `kubectl describe nodes`.

4. **Check for Pending PVCs**: If your pod is using Persistent Volume Claims (PVCs), make sure they are bound and available. Use `kubectl get pvc -n grafana-monitoring` to check the status of PVCs.

5. **Review Configurations**: Ensure that all configurations, such as ConfigMaps and Secrets, are correctly set up and accessible by the pod.

Here's an example of how you might check the pod status:

```sh
kubectl get pods -n grafana-monitoring
```

@rifaterdemsahin ➜ /workspaces/grafana-dashboard (main) $ kubectl get pods -n grafana-monitoring
NAME                       READY   STATUS       RESTARTS      AGE
grafana-756b7f7cc4-xj6zx   0/1     Init:Error   4 (52s ago)   99s
@rifaterdemsahin ➜ /workspaces/grafana-dashboard (main) $ 

And to describe the pod:

```sh
kubectl describe pod <pod-name> -n grafana-monitoring
kubectl describe pod grafana-756b7f7cc4-xj6zx -n grafana-monitoring
grafana-756b7f7cc4-xj6zx
```

Try these steps and let me know if you find any specific errors or issues. I'm here to help!


@rifaterdemsahin ➜ /workspaces/grafana-dashboard (main) $ kubectl describe pod grafana-756b7f7cc4-xj6zx -n grafana-monitoring
Name:             grafana-756b7f7cc4-xj6zx
Namespace:        grafana-monitoring
Priority:         0
Service Account:  grafana
Node:             minikube/192.168.49.2
Start Time:       Thu, 09 Jan 2025 13:28:26 +0000
Labels:           app.kubernetes.io/component=grafana
                  app.kubernetes.io/instance=grafana
                  app.kubernetes.io/managed-by=Helm
                  app.kubernetes.io/name=grafana
                  app.kubernetes.io/version=11.4.0
                  helm.sh/chart=grafana-11.4.2
                  pod-template-hash=756b7f7cc4
Annotations:      checksum/config: 19c20dc5bd07bc522511ffab5d9eac1446dcd3a6450e7bbfdf09a5d562286cec
                  checksum/dashboard-provider: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
                  checksum/secret: 4392d22dc063d7ffda1126edc47da819eefc80a1e3130abeb719c2232887e531
Status:           Pending
IP:               10.244.0.3
IPs:
  IP:           10.244.0.3
Controlled By:  ReplicaSet/grafana-756b7f7cc4
Init Containers:
  init-chmod-data:
    Container ID:  docker://bd2b7b444df54073d84a9a8113eb76f43fa5efea98282f290a46dc34790b51dd
    Image:         busybox
    Image ID:      docker-pullable://busybox@sha256:2919d0172f7524b2d8df9e50066a682669e6d170ac0f6a49676d54358fe970b5
    Port:          <none>
    Host Port:     <none>
    Command:
      sh
      -c
      chmod -R 777 /var/lib/grafana
    State:          Waiting
      Reason:       CrashLoopBackOff
    Last State:     Terminated
      Reason:       Error
      Exit Code:    1
      Started:      Thu, 09 Jan 2025 13:30:01 +0000
      Finished:     Thu, 09 Jan 2025 13:30:01 +0000
    Ready:          False
    Restart Count:  4
    Environment:    <none>
    Mounts:
      /opt/bitnami/grafana from grafana-storage (rw)
  install-ping:
    Container ID:  
    Image:         alpine
    Image ID:      
    Port:          <none>
    Host Port:     <none>
    Command:
      sh
      -c
      apk add --no-cache iputils && sleep 1
    State:          Waiting
      Reason:       PodInitializing
    Ready:          False
    Restart Count:  0
    Environment:    <none>
    Mounts:         <none>
Containers:
  grafana:
    Container ID:    
    Image:           docker.io/bitnami/grafana:11.4.0-debian-12-r0
    Image ID:        
    Port:            3000/TCP
    Host Port:       0/TCP
    SeccompProfile:  RuntimeDefault
    State:           Waiting
      Reason:        PodInitializing
    Ready:           False
    Restart Count:   0
    Limits:
      cpu:                150m
      ephemeral-storage:  2Gi
      memory:             192Mi
    Requests:
      cpu:                100m
      ephemeral-storage:  50Mi
      memory:             128Mi
    Liveness:             tcp-socket :dashboard delay=120s timeout=5s period=10s #success=1 #failure=6
    Readiness:            http-get http://:dashboard/api/health delay=30s timeout=5s period=10s #success=1 #failure=6
    Environment Variables from:
      grafana-envvars  ConfigMap  Optional: false
    Environment:
      GF_SECURITY_ADMIN_PASSWORD:  <set to the key 'GF_SECURITY_ADMIN_PASSWORD' in secret 'grafana-admin'>  Optional: false
    Mounts:
      /bitnami/grafana from empty-dir (rw,path="app-volume-dir")
      /opt/bitnami/grafana/conf from empty-dir (rw,path="app-conf-dir")
      /opt/bitnami/grafana/dashboards/dashboards/grafana_dashboard_config.json from grafana-dashboard-config (rw,path="grafana_dashboard_config.json")
      /opt/bitnami/grafana/data from data (rw)
      /opt/bitnami/grafana/tmp from empty-dir (rw,path="app-tmp-dir")
      /tmp from empty-dir (rw,path="tmp-dir")
Conditions:
  Type                        Status
  PodReadyToStartContainers   True 
  Initialized                 False 
  Ready                       False 
  ContainersReady             False 
  PodScheduled                True 
Volumes:
  empty-dir:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     
    SizeLimit:  <unset>
  data:
    Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
    ClaimName:  grafana
    ReadOnly:   false
  grafana-dashboard-config:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      grafana-dashboard-config
    Optional:  false
  grafana-storage:
    Type:        EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:      
    SizeLimit:   <unset>
QoS Class:       Burstable
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason            Age                  From               Message
  ----     ------            ----                 ----               -------
  Warning  FailedScheduling  2m16s                default-scheduler  0/1 nodes are available: pod has unbound immediate PersistentVolumeClaims. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling.
  Normal   Scheduled         2m14s                default-scheduler  Successfully assigned grafana-monitoring/grafana-756b7f7cc4-xj6zx to minikube
  Normal   Pulled            2m11s                kubelet            Successfully pulled image "busybox" in 1.845s (1.845s including waiting). Image size: 4269678 bytes.
  Normal   Pulled            2m10s                kubelet            Successfully pulled image "busybox" in 729ms (729ms including waiting). Image size: 4269678 bytes.
  Normal   Pulled            115s                 kubelet            Successfully pulled image "busybox" in 717ms (717ms including waiting). Image size: 4269678 bytes.
  Normal   Created           89s (x4 over 2m11s)  kubelet            Created container init-chmod-data
  Normal   Started           89s (x4 over 2m11s)  kubelet            Started container init-chmod-data
  Normal   Pulled            89s                  kubelet            Successfully pulled image "busybox" in 721ms (721ms including waiting). Image size: 4269678 bytes.
  Warning  BackOff           55s (x8 over 2m10s)  kubelet            Back-off restarting failed container init-chmod-data in pod grafana-756b7f7cc4-xj6zx_grafana-monitoring(43814f4f-0d6f-441a-be67-bfcd2aac3a87)
  Normal   Pulling           40s (x5 over 2m13s)  kubelet            Pulling image "busybox"
@rifaterdemsahin ➜ /workspaces/grafana-dashboard (main) $ 

---

It looks like the `init-chmod-data` init container is stuck in a `CrashLoopBackOff` state due to an error. The error seems to be related to the `chmod -R 777 /var/lib/grafana` command. Here are a few steps you can take to troubleshoot and resolve this issue:

1. **Check the Volume Mount**: Ensure that the volume mount `/var/lib/grafana` is correctly configured and accessible. It might be helpful to verify the permissions and existence of this directory.

2. **Modify the Init Container Command**: Sometimes, the `chmod` command might fail due to various reasons. You can try modifying the command to see if it provides more information or resolves the issue. For example, you can add a `ls -l /var/lib` before the `chmod` command to check the directory's contents and permissions.

3. **Persistent Volume Claim (PVC)**: The events indicate that there is an issue with the PVC. Ensure that the PVC named `grafana` is correctly bound and available. You can check the status of the PVC with the following command:
   ```sh
   kubectl get pvc -n grafana-monitoring
   ```

4. **Logs**: Check the logs of the init container to get more details about the error. You can use the following command to view the logs:
   ```sh
   kubectl logs <pod-name> -c init-chmod-data -n grafana-monitoring
   ```

Here's an example of how you might modify the init container command in your YAML file:

```yaml
initContainers:
- name: init-chmod-data
  image: busybox
  command:
    - sh
    - -c
    - |
      ls -l /var/lib
      chmod -R 777 /var/lib/grafana
  volumeMounts:
    - name: grafana-storage
      mountPath: /var/lib/grafana
```

Try these steps and let me know if you find any specific errors or issues. I'm here to help!
